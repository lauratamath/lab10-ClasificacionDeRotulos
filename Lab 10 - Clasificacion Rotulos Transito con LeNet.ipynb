{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación de rótulos de tránsito (EEUU) utilizando la arquitectura de CNN Le_Net  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enunciado del problema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lo largo del tiempo, se han desarrollado muchas arquitecturas de redes neuronales, algunas de ellas se han vuelto clásicas.  Una de ellas es una CNN (red neuronal convolucional) desarrollada por Yann LeCun a la que le denominó Le-Net.  Pueden ver el artículo original en:\n",
    "\n",
    "http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf\n",
    "\n",
    "El diseño es el siguiente:\n",
    "\n",
    "![Arquitectura Le-Net](../Images/Le-Net.png)\n",
    "\n",
    "* C: Capa de Convolución, \n",
    "* S: Capa de Submuestreo (Pooling), \n",
    "* F: Capa completamente conectada (Fully Connected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso de estudio, se proveen imágenes de rótulos de tráfico y el objetivo es entrenar una red Le-Net para que las pueda clasificar\n",
    "\n",
    "- El conjunto de datos contiene 43 clases diferentes de imágenes. \n",
    "- Las clases se listan abajo: \n",
    "\n",
    "    0 - Limite velocidad (20km/h)  \n",
    "    1 - Limite velocidad (30km/h)  \n",
    "    2 - Limite velocidad (50km/h)  \n",
    "    3 - Limite velocidad (60km/h)  \n",
    "    4 - Limite velocidad (70km/h)  \n",
    "    5 - Limite velocidad (80km/h)  \n",
    "    6 - Fin de limite velocidad (80km/h)'  \n",
    "    7 - Limite velocidad (100km/h)  \n",
    "    8 - Limite velocidad (120km/h)  \n",
    "    9 - No rebasar  \n",
    "    10 - No rebasar para vehiculos mayores de 3.5 tonladas metricas  \n",
    "    11 - Derecho-de-via en la siguiente interseccion  \n",
    "    12 - Camino prioritario  \n",
    "    13 - Ceda el paso  \n",
    "    14 - Alto  \n",
    "    15 - No vehiculos  \n",
    "    16 - Prohibido vehiculos mayores de 3.5 toneladas metricas  \n",
    "    17 - No hay entrada\n",
    "    18 - Precaucion general  \n",
    "    19 - Curva peligrosa a la izquierda  \n",
    "    20 - Curva peligrosa a la derecha  \n",
    "    21 - Doble curva  \n",
    "    22 - Camino disparejo  \n",
    "    23 - Camino resbaloso  \n",
    "    24 - Camino se reduce a la derecha  \n",
    "    25 - Trabajos adelante  \n",
    "    26 - Señales de Trafico -semaforos-  \n",
    "    27 - Cruce de peatones  \n",
    "    28 - Cruce de Niños  \n",
    "    29 - Cruce de bicicletas  \n",
    "    30 - Cuidado hielo/nieve  \n",
    "    31 - Cruce de animales silvestres  \n",
    "    32 - Fin de todos los limites de velocidad y rebase  \n",
    "    33 - Gire a la derecha adelante  \n",
    "    34 - Gire a la izquierda adelante  \n",
    "    35 - Recto solo  \n",
    "    36 - Vaya recto o a la rerecha  \n",
    "    37 - Vaya recto o a la izquierda  \n",
    "    38 - Mantengase a la derecha  \n",
    "    39 - Mantengase a la izquierda  \n",
    "    40 - Vuelta en U obligada  \n",
    "    41 - Fin de no rebasar  \n",
    "    42 - Fin de no rebasar para vehiculos mayores de 3.5 toneladas metricas\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Referencias (Señales de Tráfico)\n",
    "\n",
    "J. Stallkamp, M. Schlipsing, J. Salmen, and C. Igel. The German Traffic Sign Recognition Benchmark: A multi-class classification competition. In Proceedings of the IEEE International Joint Conference on Neural Networks, pages 1453–1460. 2011. \n",
    "\n",
    "@inproceedings{Stallkamp-IJCNN-2011,\n",
    "    author = {Johannes Stallkamp and Marc Schlipsing and Jan Salmen and Christian Igel},\n",
    "    booktitle = {IEEE International Joint Conference on Neural Networks},\n",
    "    title = {The {G}erman {T}raffic {S}ign {R}ecognition {B}enchmark: A multi-class classification competition},\n",
    "    year = {2011},\n",
    "    pages = {1453--1460}\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTAR LIBRERIAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtener Datos\n",
    "\n",
    "El módulo de Pickle implementa protocolos binarios para la serialización y de-serialización de objetos Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"entrenamiento.p\", mode='rb') as datos_entreno:\n",
    "    entreno = pickle.load(datos_entreno)\n",
    "with open(\"validacion.p\", mode='rb') as datos_validacion:\n",
    "    valida = pickle.load(datos_validacion)\n",
    "with open(\"prueba.p\", mode='rb') as datos_prueba:\n",
    "    prueba = pickle.load(datos_prueba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_entreno, y_entreno = entreno['features'], entreno['labels']\n",
    "X_valida, y_valida = valida['features'], valida['labels']\n",
    "X_prueba, y_prueba = prueba['features'], prueba['labels']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPLORACION DE LAS IMAGENES\n",
    "\n",
    "Mostrar que las imágenes no están \"barajeadas\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numero de ejemplos de entreno\n",
    "n_entreno = X_entreno.shape[0]\n",
    "\n",
    "# Numero de ejemplos de validacion\n",
    "n_validacion = X_valida.shape[0]\n",
    "\n",
    "# Numero de ejemplos de prueba\n",
    "n_prueba = X_prueba.shape[0]\n",
    "\n",
    "# TODO: tamaño de las imagenes de señales de trancito  \n",
    "image_shape = X_entreno.shape[1:4]\n",
    "\n",
    "# Numero de clases\n",
    "n_classes = np.unique(ar=y_entreno).shape[0]\n",
    "\n",
    "image_depth_dimension = X_entreno.shape[3]\n",
    "\n",
    "print(\"Number of training examples =\", n_entreno)\n",
    "print(\"Number of testing examples =\", n_prueba)\n",
    "print(\"Image data shape =\", image_shape)\n",
    "print(\"Number of classes =\", n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPARACION DE LOS DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Barajear\" los datos\n",
    "#funcion qeu agrra las imagenes de los dataset y los muestra\n",
    "def plot_digits(X, Y):\n",
    "    %matplotlib inline\n",
    "    fig=plt.figure(figsize=(16, 16))\n",
    "    columns = 9\n",
    "    rows = 10\n",
    "    for i in range(1, columns*rows +1):\n",
    "        # show random images from the dataset\n",
    "        img = X[randint(0, Y-1)]\n",
    "        fig.add_subplot(rows, columns, i)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')   \n",
    "    plt.show()\n",
    "\n",
    "plot_digits(X_entreno, n_entreno)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_digits(X_valida, n_validacion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_digits(X_prueba, n_prueba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizar los datos\n",
    "def normalize(x):\n",
    "    min_val = np.min(x)\n",
    "    max_val = np.max(x)\n",
    "    x = (x-min_val) / (max_val-min_val)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_train = np.zeros([n_entreno,32,32,3])\n",
    "normalized_validation = np.zeros([n_validacion,32,32,3])\n",
    "normalized_test = np.zeros([n_prueba,32,32,3])\n",
    "for i in range(0,n_entreno):\n",
    "    normalized_train[i] = normalize(X_entreno[i])\n",
    "for i in range(0,n_validacion):\n",
    "    normalized_validation[i] = normalize(X_valida[i])\n",
    "for i in range(0,n_prueba):\n",
    "    normalized_test[i] = normalize(X_prueba[i])\n",
    "\n",
    "assert(X_entreno.shape==normalized_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(nrows=2,ncols=2,figsize = (16,16))\n",
    "randomindex = randint(0,n_entreno-1)\n",
    "axarr[0,0].imshow(X_entreno[randomindex])\n",
    "axarr[0,0].axis('off')\n",
    "axarr[0,0].set_title('Imagen Original')\n",
    "axarr[0,1].imshow(normalized_train[randomindex])\n",
    "axarr[0,1].axis('off')\n",
    "axarr[0,1].set_title('Imagen Normalizada')\n",
    "randomindex = randint(0,n_entreno-1)\n",
    "axarr[1,0].imshow(X_entreno[randomindex])\n",
    "axarr[1,0].axis('off')\n",
    "axarr[1,0].set_title('Imagen Original')\n",
    "axarr[1,1].imshow(normalized_train[randomindex])\n",
    "axarr[1,1].axis('off')\n",
    "axarr[1,1].set_title('Imagen Normalizada')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir imágenes a blanco y negro\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_entreno = normalized_train\n",
    "\n",
    "X_validacion = normalized_validation\n",
    "\n",
    "X_prueba = normalized_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo consiste de las siguientes capas: \n",
    "\n",
    "- Paso 1: La primera capa convolucional #1\n",
    "\n",
    "    - Entrada = 32x32x1\n",
    "    - Salida = 28x28x6\n",
    "    - Salida = (Entrada-filtro+1)/Paso* => (32-5+1)/1=28\n",
    "    - Se utiliza un filtro de 5x5 con una profundidad de entrada 3 y profundidad de salida 6\n",
    "    - Aplicar una función de activación RELU a la salida\n",
    "    - Submuestreo (pooling) para la entrada, Entrada = 28x28x6 y Salida = 14x14x6\n",
    "\n",
    "\n",
    "    * Paso (Stride) es la cantidad por la cual el kernel se desplaza cuando el kernel se pasa sobre la imagen.\n",
    "\n",
    "- Paso 2: La segunda capa covolucional #2\n",
    "\n",
    "    - Entrada = 14x14x6\n",
    "    - Salida = 10x10x16\n",
    "    - Capa 2: Capa convolutional con salida = 10x10x16\n",
    "    - Output = (Input-filter+1)/strides => 10 = 14-5+1/1\n",
    "    - Aplicar una función de activación RELU a la salida\n",
    "    - Submuestreo (pooling) con Entrada = 10x10x16 Salida = 5x5x16\n",
    "\n",
    "- Paso 3: \"Aplanar\" la red (convertir a una dimensión)\n",
    "\n",
    "    - Entrada = 5x5x16 y Salida = 400\n",
    "\n",
    "- Paso 4: Capa plenamenente conectada\n",
    "\n",
    "    - Capa 3: Capa plenamente conectada con Entrada = 400 y Salida = 120\n",
    "    - Aplicar una función de activación RELU a la salida\n",
    "\n",
    "- Paso 5: Otra capa plenamente conectada\n",
    "\n",
    "    - Capa 4: Capa plenamente conectada con Entrada = 120 y Salida = 84\n",
    "    - Aplicar una función de activación RELU a la salida\n",
    "\n",
    "- Paso 6: Otra capa plenamente conectada\n",
    "\n",
    "    - Capa 5: Capa plenamente conectada con Entrada = 84 y Salida = 43"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importar librerías para construir el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Conv2D, Dense, Flatten, Rescaling, AveragePooling2D, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el modelo\n",
    "model = Sequential([\n",
    "    Rescaling(1, input_shape=(32, 32, 3)),\n",
    "    Conv2D(filters=6, kernel_size=(5, 5), activation='relu'),\n",
    "    AveragePooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(filters=16, kernel_size=(5, 5), activation='relu'),\n",
    "    AveragePooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(filters=400, kernel_size=(5, 5), activation='relu'),\n",
    "    Dropout(0.2), \n",
    "    Flatten(),\n",
    "    Dense(units=120, activation='relu'),\n",
    "    Dense(units=42, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilar el modelo\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo y guardar los datos en un hhistorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVALUACION DEL MODELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el modelo e indicar la exactitud con los datos de prueba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar gráfica de Exactitud y de Entrenamiento y Validación\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar gráfica de Pérdida de Entrenamiento y Validación\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtener las predicciones para los datos de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  A partir de la versión 2.6 de tensorflow, la siguiente instrucción\n",
    "#    puede dar el error:  ‘Sequential’ object has no attribute ‘predict_classes’\n",
    "#    por lo que se sustituye por la que le sigue\n",
    "#\n",
    "#clases_predichas = modelo_cnn.predict_classes(X_prueba_gris_norm)\n",
    "\n",
    "clases_predichas = np.argmax(modelo_cnn.predict(X_prueba_BN_norm),axis=1)\n",
    "\n",
    "# se obtienen los índices para poder graficar\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar un mapa de calor para la matriz de confusión\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generar un cuadro de 7 X 7 con los primeros 49 rótulos del conjunto de prueba y \n",
    "#   para cada uno colocar de título la etiqueta verdadera y el código predicho por el \n",
    "#   modelo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Ajustes del modelo\n",
    "\n",
    "Como se puede ver, hay muchos lugares donde se puede cambiar la configuración del modelo.  A continuación se sugieren varias posibilidades que deben probar e indicar si se mejora la exactitud del modelo:\n",
    "\n",
    "1. Incrementar el número de épocas para el entrenamiento a 500 ó 1,000\n",
    "2. En las capas de convolución cambiar el tamaño del kernel a 10 X 10\n",
    "3. Cambiar el método de submuestrear (pooling) a MaxPooling\n",
    "4. Cambiar el numero de la segunda capa plenamente conectada de 84 a 100 unidades\n",
    "5. Cambiar el número de la primera capa plenamente conectada de 120 a 300 unidades\n",
    "\n",
    "La idea es ir haciendo los cambios uno por uno y ver cómo va cambiando la exactitud del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b2e82e792ab2fe1f79a1681212c8a0df90a82b1b30c69f8528b93f57968011e2"
   }
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
